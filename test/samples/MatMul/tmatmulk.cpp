#include "pto/pto-inst.hpp"
using namespace pto;

	template <typename To, typename From>
	static inline To ptoas_bitcast(From from) {
	  static_assert(sizeof(To) == sizeof(From), "ptoas_bitcast: size mismatch");
	  To to;
	  __builtin_memcpy(&to, &from, sizeof(To));
	  return to;
	}
	
__global__ AICORE void RunTMATMULSplitK(__gm__ float* v1, __gm__ float* v2, __gm__ float* v3, __gm__ float* v4, bool v5) {
  int64_t v6;
  int64_t v7;
  int64_t v8;
  int32_t v9;
  size_t v10;
  int32_t v11;
  size_t v12;
  int32_t v13;
  int32_t v14;
  int32_t v15;
  size_t v16;
  Tile<TileType::Mat, float, 32, 32, BLayout::ColMajor, 32, 32, SLayout::RowMajor, 512, PadValue::Null> v17;
  Tile<TileType::Mat, float, 32, 32, BLayout::ColMajor, 32, 32, SLayout::RowMajor, 512, PadValue::Null> v18;
  Tile<TileType::Mat, float, 1, 32, BLayout::RowMajor, 1, 32, SLayout::NoneBox, 512, PadValue::Null> v19;
  Tile<TileType::Left, float, 32, 32, BLayout::RowMajor, 32, 32, SLayout::RowMajor, 512, PadValue::Null> v20;
  Tile<TileType::Right, float, 32, 32, BLayout::RowMajor, 32, 32, SLayout::ColMajor, 512, PadValue::Null> v21;
  Tile<TileType::Acc, float, 32, 32, BLayout::ColMajor, 32, 32, SLayout::RowMajor, 1024, PadValue::Null> v22;
  Tile<TileType::Bias, float, 1, 32, BLayout::RowMajor, 1, 32, SLayout::NoneBox, 512, PadValue::Null> v23;
  int32_t v24;
  uint32_t v25;
  uint32_t v26;
  uint32_t v27;
  int32_t v28;
  unsigned v29;
  unsigned v30;
  unsigned v31;
  unsigned v32;
  unsigned v33;
  unsigned v34;
  unsigned v35;
  unsigned v36;
  unsigned v37;
  unsigned v38;
  unsigned v39;
  __gm__ float* v40;
  pto::Shape<1, 1, 1, 32, 32> v41;
  pto::Stride<8192, 8192, 8192, 256, 1> v42;
  GlobalTensor<float, pto::Shape<1, 1, 1, 32, 32>, pto::Stride<8192, 8192, 8192, 256, 1>, pto::Layout::ND> v43(nullptr);
  unsigned v44;
  unsigned v45;
  unsigned v46;
  unsigned v47;
  unsigned v48;
  unsigned v49;
  unsigned v50;
  unsigned v51;
  unsigned v52;
  unsigned v53;
  unsigned v54;
  __gm__ float* v55;
  pto::Shape<1, 1, 1, 32, 32> v56;
  pto::Stride<1024, 1024, 1024, 32, 1> v57;
  GlobalTensor<float, pto::Shape<1, 1, 1, 32, 32>, pto::Stride<1024, 1024, 1024, 32, 1>, pto::Layout::ND> v58(nullptr);
  unsigned v59;
  unsigned v60;
  unsigned v61;
  unsigned v62;
  unsigned v63;
  unsigned v64;
  unsigned v65;
  unsigned v66;
  unsigned v67;
  unsigned v68;
  unsigned v69;
  __gm__ float* v70;
  pto::Shape<1, 1, 1, 1, 32> v71;
  pto::Stride<32, 32, 32, 32, 1> v72;
  GlobalTensor<float, pto::Shape<1, 1, 1, 1, 32>, pto::Stride<32, 32, 32, 32, 1>, pto::Layout::ND> v73(nullptr);
  bool v74;
  unsigned v75;
  unsigned v76;
  unsigned v77;
  unsigned v78;
  unsigned v79;
  unsigned v80;
  unsigned v81;
  unsigned v82;
  unsigned v83;
  unsigned v84;
  unsigned v85;
  __gm__ float* v86;
  pto::Shape<1, 1, 1, 32, 32> v87;
  pto::Stride<1024, 1024, 1024, 32, 1> v88;
  GlobalTensor<float, pto::Shape<1, 1, 1, 32, 32>, pto::Stride<1024, 1024, 1024, 32, 1>, pto::Layout::ND> v89(nullptr);
  using T = float;
  v6 = 8192;
  v7 = 4096;
  v8 = 0;
  v9 = 0;
  v10 = (size_t) v9;
  v11 = 1;
  v12 = (size_t) v11;
  v13 = 32;
  v14 = 256;
  v15 = 8;
  v16 = (size_t) v15;
  ;
  TASSIGN(v17, v8);
  ;
  TASSIGN(v18, v7);
  ;
  TASSIGN(v19, v6);
  ;
  TASSIGN(v20, v8);
  ;
  TASSIGN(v21, v8);
  ;
  TASSIGN(v22, v8);
  ;
  TASSIGN(v23, v8);
  for (size_t v90 = v10; v90 < v16; v90 += v12) {
    v24 = (int32_t) v90;
    v25 = (uint32_t) v24;
    v26 = (uint32_t) v13;
    v27 = v25 * v26;
    v28 = (int32_t) v27;
    v29 = 0;
    v30 = 0;
    v31 = 1;
    v32 = (unsigned) v14;
    v33 = v30 * v32;
    v34 = v29 + v33;
    v35 = (unsigned) v28;
    v36 = 1;
    v37 = (unsigned) v11;
    v38 = v35 * v37;
    v39 = v34 + v38;
    v40 = v2 + v39;
    v41 = pto::Shape<1, 1, 1, 32, 32>();
    v42 = pto::Stride<8192, 8192, 8192, 256, 1>();
    v43 = GlobalTensor<float, pto::Shape<1, 1, 1, 32, 32>, pto::Stride<8192, 8192, 8192, 256, 1>, pto::Layout::ND>(v40, v41, v42);
    v44 = 0;
    v45 = (unsigned) v28;
    v46 = 1;
    v47 = (unsigned) v13;
    v48 = v45 * v47;
    v49 = v44 + v48;
    v50 = 0;
    v51 = 1;
    v52 = (unsigned) v11;
    v53 = v50 * v52;
    v54 = v49 + v53;
    v55 = v3 + v54;
    v56 = pto::Shape<1, 1, 1, 32, 32>();
    v57 = pto::Stride<1024, 1024, 1024, 32, 1>();
    v58 = GlobalTensor<float, pto::Shape<1, 1, 1, 32, 32>, pto::Stride<1024, 1024, 1024, 32, 1>, pto::Layout::ND>(v55, v56, v57);
    v59 = 0;
    v60 = 0;
    v61 = 1;
    v62 = (unsigned) v13;
    v63 = v60 * v62;
    v64 = v59 + v63;
    v65 = 0;
    v66 = 1;
    v67 = (unsigned) v11;
    v68 = v65 * v67;
    v69 = v64 + v68;
    v70 = v4 + v69;
    v71 = pto::Shape<1, 1, 1, 1, 32>();
    v72 = pto::Stride<32, 32, 32, 32, 1>();
    v73 = GlobalTensor<float, pto::Shape<1, 1, 1, 1, 32>, pto::Stride<32, 32, 32, 32, 1>, pto::Layout::ND>(v70, v71, v72);
    TLOAD(v17, v43);
    TLOAD(v18, v58);
    if (v5) {
      TLOAD(v19, v73);
    } else {
    };
    set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    TMOV(v20, v17);
    TMOV(v21, v18);
    if (v5) {
      TMOV(v23, v19);
    } else {
    };
    set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
    wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
    v74 = v24 == v9;
    if (v74) {
      if (v5) {
        TMATMUL_BIAS(v22, v20, v21, v23);
      } else {
        TMATMUL(v22, v20, v21);
      };
    } else {
      TMATMUL_ACC(v22, v22, v20, v21);
    };
    set_flag(PIPE_M, PIPE_MTE2, EVENT_ID0);
    wait_flag(PIPE_M, PIPE_MTE2, EVENT_ID0);
  }
  set_flag(PIPE_M, PIPE_FIX, EVENT_ID0);
  wait_flag(PIPE_M, PIPE_FIX, EVENT_ID0);
  v75 = 0;
  v76 = 0;
  v77 = 1;
  v78 = (unsigned) v13;
  v79 = v76 * v78;
  v80 = v75 + v79;
  v81 = 0;
  v82 = 1;
  v83 = (unsigned) v11;
  v84 = v81 * v83;
  v85 = v80 + v84;
  v86 = v1 + v85;
  v87 = pto::Shape<1, 1, 1, 32, 32>();
  v88 = pto::Stride<1024, 1024, 1024, 32, 1>();
  v89 = GlobalTensor<float, pto::Shape<1, 1, 1, 32, 32>, pto::Stride<1024, 1024, 1024, 32, 1>, pto::Layout::ND>(v86, v87, v88);
  TSTORE(v89, v22);
  return;
}

